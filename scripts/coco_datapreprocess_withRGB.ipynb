{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a62760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import pickle\n",
    "from collections import defaultdict,Counter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb930da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021750b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clsNum = 123\n",
    "pickleDir = '/home/k100/Code/motionclassifiation_trainData_process/pyskl/data'\n",
    "# picklePath = f'{pickleDir}/yolov8_stgcnpptrain4SHOW_20230915_cls_10.pkl'\n",
    "picklePath = f'{pickleDir}/yolov8_stgcnpp_123_20241008.pkl'\n",
    "save_path = '.'\n",
    "save_data_pkl = 'test.pkl'\n",
    "frames_drop_pkl = 'frames_drop_skes_test.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00f558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(labels):\n",
    "    num_skes = len(labels)\n",
    "    labels_vector = np.zeros((num_skes, clsNum))\n",
    "    for idx, l in enumerate(labels):\n",
    "        labels_vector[idx, l] = 1\n",
    "\n",
    "    return labels_vector\n",
    "\n",
    "def normalization(data,frameShape=(1080,1920)):\n",
    "    height,width = frameShape\n",
    "    data[...,0]/=width\n",
    "    data[...,1]/=height\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_dataset(skes_joints, labels, performer, camera, evaluation, save_path):\n",
    "    print(performer.shape,camera.shape)\n",
    "    train_indices, test_indices = get_indices(performer, camera, evaluation)\n",
    "    m = 'sklearn'  # 'sklearn' or 'numpy'\n",
    "    train_labels = labels[train_indices]\n",
    "    test_labels = labels[test_indices]\n",
    "    print('[train_indices] : ', len(train_indices))\n",
    "    train_x = skes_joints[train_indices]\n",
    "    train_y = one_hot_vector(train_labels)\n",
    "    test_x = skes_joints[test_indices]\n",
    "    test_y = one_hot_vector(test_labels)\n",
    "    print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)\n",
    "    save_name = save_path + f'/NTU60_{evaluation}.npz'\n",
    "    np.savez(save_name, x_train=train_x, y_train=train_y, x_test=test_x, y_test=test_y)\n",
    "\n",
    "\n",
    "def get_indices(performer, camera, evaluation='CS'):\n",
    "    test_indices = np.empty(0)\n",
    "    train_indices = np.empty(0)\n",
    "\n",
    "    if evaluation == 'CS':  # Cross Subject (Subject IDs)\n",
    "        train_ids = [1,  2,  4,  5,  8,  9,  13, 14, 15, 16,\n",
    "                     17, 18, 19, 25, 27, 28, 31, 34, 35, 38]\n",
    "        test_ids = [3,  6,  7,  10, 11, 12, 20, 21, 22, 23,\n",
    "                    24, 26, 29, 30, 32, 33, 36, 37, 39, 40]\n",
    "\n",
    "        # Get indices of test data\n",
    "        for idx in test_ids:\n",
    "            temp = np.where(performer == idx)[0]  # 0-based index\n",
    "            test_indices = np.hstack((test_indices, temp)).astype(np.int)\n",
    "\n",
    "        # Get indices of training data\n",
    "        for train_id in train_ids:\n",
    "            temp = np.where(performer == train_id)[0]  # 0-based index\n",
    "            train_indices = np.hstack((train_indices, temp)).astype(np.int)\n",
    "    else:  # Cross View (Camera IDs)\n",
    "        train_ids = [2, 3]\n",
    "        test_ids = 1\n",
    "        # Get indices of test data\n",
    "        temp = np.where(camera == test_ids)[0]  # 0-based index\n",
    "        test_indices = np.hstack((test_indices, temp)).astype(np.int)\n",
    "\n",
    "        # Get indices of training data\n",
    "        for train_id in train_ids:\n",
    "            temp = np.where(camera == train_id)[0]  # 0-based index\n",
    "            train_indices = np.hstack((train_indices, temp)).astype(np.int)\n",
    "    return train_indices, test_indices\n",
    "\n",
    "def get_video_last_frame(vname):\n",
    "    if not os.path.exists(vname):\n",
    "        return None,None\n",
    "    cap = cv2.VideoCapture(vname)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, cap.get(cv2.CAP_PROP_FRAME_COUNT) - 1)\n",
    "    ret, last_frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    return ret,last_frame\n",
    "\n",
    "def xywh2xyxy(bbox):\n",
    "    xc,yc,w,h = bbox\n",
    "    x1 = xc - (w/2)\n",
    "    y1 = yc - (h/2)\n",
    "    x2 = xc + (w/2)\n",
    "    y2 = yc + (h/2)\n",
    "    return [x1,y1,x2,y2]\n",
    "\n",
    "def xyxy2xywh(bbox):\n",
    "    x1,y1,x2,y2 = bbox\n",
    "    xc = (x1+x2)/2\n",
    "    yc = (y1+y2)/2\n",
    "    w = x2-x1\n",
    "    h = y2-y1\n",
    "    return [xc,yc,w,h]\n",
    "\n",
    "def getBBOX_from_kpt(kpt,outsize=2):\n",
    "    x1 = np.min(anno['keypoint'][:,-1,:,0])\n",
    "    y1 = np.min(anno['keypoint'][:,-1,:,1])\n",
    "    x2 = np.max(anno['keypoint'][:,-1,:,0])\n",
    "    y2 = np.max(anno['keypoint'][:,-1,:,1])\n",
    "    xc,yc,w,h = xyxy2xywh([x1,y1,x2,y2])\n",
    "    w *= outsize\n",
    "    h *= outsize\n",
    "    x1,y1,x2,y2 = xywh2xyxy([xc,yc,w,h])\n",
    "    bbox = np.array([x1,y1,x2,y2]).astype(int)\n",
    "    bbox[bbox<0] = 0\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be78a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(picklePath,'rb') as f:\n",
    "    datas = pickle.load(f)\n",
    "annotations = datas['annotations']\n",
    "annotations = annotations#[:10]\n",
    "# xsub_train = datas['split']['xsub_train']\n",
    "# xsub_val = datas['split']['xsub_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741c2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasPath = '/run/user/1001/gvfs/smb-share:server=10.173.1.14,share=shared_folders/stgcnpp_dataset/ntu_rgbd_120/videos'\n",
    "saveRGBPath = '/home/k100/Code/motionclassifiation_trainData_process/RGB_lastFrame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14852dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_780968/1031592507.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  frames_cnt = np.zeros(len(annotations), dtype=np.int)\n",
      "1139105it [00:00, 2424781.28it/s]\n",
      "[data no] : 100%|█████████████████████████████████████████████████████████████████████| 1139105/1139105 [00:10<00:00, 107874.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1139105, 100, 102), 215637, 215637)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    pbar.close()\n",
    "except:\n",
    "    pass\n",
    "frames_cnt = np.zeros(len(annotations), dtype=np.int)\n",
    "for annoIdx,anno in tqdm(enumerate(annotations)):\n",
    "    frames_cnt[annoIdx] = anno['total_frames']\n",
    "# max_num_frames = frames_cnt.max()  # 300\n",
    "max_num_frames = 100\n",
    "\n",
    "## =====================================================================\n",
    "\n",
    "aligned_skes_joints = np.zeros((len(annotations), max_num_frames, 51*2), dtype=np.float32)\n",
    "labels = []\n",
    "# crops = []\n",
    "crops_names = []\n",
    "pbar = tqdm(total=len(annotations),desc = '[data no] : ')\n",
    "count = 0\n",
    "for annoIdx,anno in enumerate(annotations):\n",
    "    pbar.update(1)\n",
    "    frame_dir = anno['frame_dir']\n",
    "    if 'rand' in frame_dir or '.txt' in frame_dir or '.png' in frame_dir or 'video_' in frame_dir:\n",
    "        continue\n",
    "    writeImgName = f'{saveRGBPath}/{frame_dir}_rgb.png'\n",
    "    if os.path.exists(writeImgName):\n",
    "        kpt = anno['keypoint']\n",
    "        kptS = anno['keypoint_score']\n",
    "        label = anno['label']\n",
    "        img_shape = anno['img_shape']\n",
    "        total_frames = anno['total_frames']\n",
    "        personNum = len(kpt)\n",
    "        frames_cnt[annoIdx] = total_frames\n",
    "        kpt2D = kpt\n",
    "        kpt = np.concatenate((kpt,np.expand_dims(kptS,-1)),axis=-1)#.shape\n",
    "        kpt = normalization(kpt).reshape(total_frames,51*personNum)\n",
    "        if total_frames > max_num_frames:\n",
    "            kpt = kpt[-max_num_frames:]\n",
    "            frames_cnt[annoIdx] = max_num_frames\n",
    "        aligned_skes_joints[count, :kpt.shape[0],:kpt.shape[-1]] = kpt\n",
    "        labels.append(label)\n",
    "        crops_names.append(f'{frame_dir}_rgb.png')\n",
    "\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        kpt = anno['keypoint']\n",
    "        x1,y1,x2,y2 = getBBOX_from_kpt(anno['keypoint'])\n",
    "        if x2-x1 < 64 or y2-y1 < 128:\n",
    "            continue\n",
    "\n",
    "        ret,lastFrame = get_video_last_frame(f'{nasPath}/{frame_dir}_rgb.avi')\n",
    "        if not ret:\n",
    "            print(f'[NOT return] : {nasPath}/{frame_dir}_rgb.avi')\n",
    "            continue\n",
    "\n",
    "\n",
    "        kptS = anno['keypoint_score']\n",
    "        label = anno['label']\n",
    "        img_shape = anno['img_shape']\n",
    "        total_frames = anno['total_frames']\n",
    "        personNum = len(kpt)\n",
    "        frames_cnt[annoIdx] = total_frames\n",
    "        kpt2D = kpt\n",
    "        kpt = np.concatenate((kpt,np.expand_dims(kptS,-1)),axis=-1)#.shape\n",
    "        kpt = normalization(kpt).reshape(total_frames,51*personNum)\n",
    "\n",
    "        if total_frames > max_num_frames:\n",
    "            kpt = kpt[-max_num_frames:]\n",
    "            frames_cnt[annoIdx] = max_num_frames\n",
    "        aligned_skes_joints[count, :kpt.shape[0],:kpt.shape[-1]] = kpt\n",
    "        labels.append(label)\n",
    "        cv2.imwrite(writeImgName,cv2.resize(lastFrame[y1:y2,x1:x2],(128,256)))\n",
    "        crops_names.append(f'{frame_dir}_rgb.png')\n",
    "        # crops.append(lastFrame[y1:y2,x1:x2])\n",
    "        count += 1\n",
    "pbar.close()\n",
    "\n",
    "aligned_skes_joints.shape,len(labels),len(crops_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3899837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((215637, 100, 102), 215637, 215637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_skes_joints = aligned_skes_joints[:len(labels)]\n",
    "aligned_skes_joints.shape,len(labels),len(crops_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2217fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data min num class is 41 with num : 422\n",
      "data max num class is 0 with num : 2241\n",
      "Average data num : 1796.975\n",
      "max train data num : 1796\n",
      "max test data num : 179\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(labels)\n",
    "min_key = min(counter, key=counter.get)\n",
    "max_key = max(counter, key=counter.get)\n",
    "max_key = max(counter, key=counter.get)\n",
    "average = sum(counter.values()) / len(counter)\n",
    "maxData_train = int(average)\n",
    "maxData_test = int(average*0.1)\n",
    "print(f'data min num class is {min_key} with num : {counter[min_key]}')\n",
    "print(f'data max num class is {max_key} with num : {counter[max_key]}')\n",
    "print(f'Average data num : {average}')\n",
    "print(f'max train data num : {maxData_train}')\n",
    "print(f'max test data num : {maxData_test}')\n",
    "\n",
    "train_val_DataNumEachClass = defaultdict(lambda:[0,0])\n",
    "for cls in counter:\n",
    "    totalDataNumEachClass = int(counter[cls])\n",
    "    trainDataNumEachClass = int(totalDataNumEachClass*0.9)\n",
    "    trainDataNumEachClass = maxData_train if trainDataNumEachClass > maxData_train else trainDataNumEachClass\n",
    "    valDataNumEachClass = totalDataNumEachClass - trainDataNumEachClass\n",
    "    valDataNumEachClass = maxData_test if valDataNumEachClass > maxData_test else valDataNumEachClass\n",
    "    train_val_DataNumEachClass[cls][0] = trainDataNumEachClass\n",
    "    train_val_DataNumEachClass[cls][1] = valDataNumEachClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70fd961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[data no] : 100%|███████████████████████████████████████████████████████████████████████| 215637/215637 [00:00<00:00, 528236.54it/s]\n"
     ]
    }
   ],
   "source": [
    "train_val_DataNumEachClassCurrent = defaultdict(lambda:[0,0])\n",
    "new_datas = []\n",
    "new_labels = []\n",
    "new_crops = []\n",
    "camera = []\n",
    "\n",
    "pbar = tqdm(total=len(aligned_skes_joints),desc = '[data no] : ')\n",
    "for dataIdx in range(len(aligned_skes_joints)):\n",
    "    aligned_skes_joint = aligned_skes_joints[dataIdx]\n",
    "    label = labels[dataIdx]\n",
    "    crop = crops_names[dataIdx]\n",
    "    pbar.update(1)\n",
    "    trainCurrentNum = train_val_DataNumEachClassCurrent[label][0]\n",
    "    valCurrentNum = train_val_DataNumEachClassCurrent[label][1]\n",
    "    trainTargetNum = train_val_DataNumEachClass[label][0]\n",
    "    valTargetNum = train_val_DataNumEachClass[label][1]\n",
    "    if trainCurrentNum>=trainTargetNum and valCurrentNum>=valTargetNum:\n",
    "        continue\n",
    "    elif trainCurrentNum>=trainTargetNum and not valCurrentNum>=valTargetNum:\n",
    "        new_datas.append(aligned_skes_joint)\n",
    "        new_labels.append(label)\n",
    "        new_crops.append(crop)\n",
    "        camera.append(1)\n",
    "        train_val_DataNumEachClassCurrent[label][1] += 1\n",
    "    elif not trainCurrentNum>=trainTargetNum and valCurrentNum>=valTargetNum:\n",
    "        new_datas.append(aligned_skes_joint)\n",
    "        new_labels.append(label)\n",
    "        new_crops.append(crop)\n",
    "\n",
    "        camera.append(2)\n",
    "        train_val_DataNumEachClassCurrent[label][0] += 1\n",
    "    else:\n",
    "        new_datas.append(aligned_skes_joint)\n",
    "        new_labels.append(label)\n",
    "        new_crops.append(crop)\n",
    "\n",
    "        add2 = random.choice([1,2])\n",
    "        if add2 == 2:\n",
    "            camera.append(2)\n",
    "            train_val_DataNumEachClassCurrent[label][0] += 1\n",
    "        else:\n",
    "            camera.append(1)\n",
    "            train_val_DataNumEachClassCurrent[label][1] += 1\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "066e7418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data min num class is 41 with num : 422\n",
      "data max num class is 0 with num : 1975\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(new_labels)\n",
    "min_key = min(counter, key=counter.get)\n",
    "max_key = max(counter, key=counter.get)\n",
    "max_key = max(counter, key=counter.get)\n",
    "average = sum(counter.values()) / len(counter)\n",
    "print(f'data min num class is {min_key} with num : {counter[min_key]}')\n",
    "print(f'data max num class is {max_key} with num : {counter[max_key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e203ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datas = np.array(new_datas)\n",
    "camera = np.array(camera)\n",
    "labels = np.array(new_labels)\n",
    "crops = np.array(new_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "868aee0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((214044,), (214044,), (214044, 100, 102))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.shape,labels.shape,new_datas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74778cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idxes = list(range(len(crops)))\n",
    "random.shuffle(rand_idxes)\n",
    "crops = crops[rand_idxes]\n",
    "labels = labels[rand_idxes]\n",
    "camera = camera[rand_idxes]\n",
    "new_datas = new_datas[rand_idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42668b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_withRGB(skes_joints, labels, performer, camera, evaluation, save_path, crops):\n",
    "    print(performer.shape,camera.shape)\n",
    "    train_indices, test_indices = get_indices(performer, camera, evaluation)\n",
    "    m = 'sklearn'  # 'sklearn' or 'numpy'\n",
    "    train_labels = labels[train_indices]\n",
    "    test_labels = labels[test_indices]\n",
    "    print('[train_indices] : ', len(train_indices))\n",
    "    train_x = skes_joints[train_indices]\n",
    "    test_x = skes_joints[test_indices]\n",
    "    x_trainCrop = crops[train_indices]\n",
    "    x_testCrop = crops[test_indices]\n",
    "    \n",
    "    train_y = one_hot_vector(train_labels)\n",
    "    test_y = one_hot_vector(test_labels)\n",
    "    print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)\n",
    "    save_name = save_path + f'/NTU120_{evaluation}_RGB_{datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")}.npz'\n",
    "    np.savez(save_name, x_train=train_x, y_train=train_y, x_test=test_x, y_test=test_y,\n",
    "             x_train_crop = x_trainCrop,x_test_crop = x_testCrop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a6013a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214044,) (214044,)\n",
      "[train_indices] :  193302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_780968/4225601981.py:56: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_indices = np.hstack((test_indices, temp)).astype(np.int)\n",
      "/tmp/ipykernel_780968/4225601981.py:61: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_indices = np.hstack((train_indices, temp)).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193302, 100, 102) (193302, 123) (20742, 100, 102) (20742, 123)\n"
     ]
    }
   ],
   "source": [
    "evaluations = [ 'CV']#'CS'\n",
    "\n",
    "performer = np.zeros(len(new_datas),dtype=int)\n",
    "save_path = './testdata'\n",
    "labels = np.array(labels)\n",
    "for evaluation in evaluations:\n",
    "    split_dataset_withRGB(aligned_skes_joints, labels, performer, camera, evaluation, save_path, crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a13ffef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae51573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
